{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pybboxes as pbx\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"../data/annotations/\"\n",
    "images_path = \"../data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = os.listdir(annotations_path)\n",
    "images = os.listdir(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name_list = []\n",
    "width_list = []\n",
    "height_list = []\n",
    "label_list = []\n",
    "x_min = []\n",
    "y_min = []\n",
    "x_max = []\n",
    "y_max = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 877/877 [00:08<00:00, 109.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(annotations))):\n",
    "    tree = ET.parse(os.path.join(annotations_path, annotations[i]))\n",
    "    root = tree.getroot()\n",
    "    img_name = root.find(\"filename\").text\n",
    "\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    for group in root.findall(\"object\"):\n",
    "        label = group.find(\"name\").text\n",
    "        bbox = group.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        img_name_list.append(img_name)\n",
    "        width_list.append(width)\n",
    "        height_list.append(height)\n",
    "        x_min.append(xmin)\n",
    "        y_min.append(ymin)\n",
    "        x_max.append(xmax)\n",
    "        y_max.append(ymax)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>road0.png</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>208</td>\n",
       "      <td>232</td>\n",
       "      <td>trafficlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road1.png</td>\n",
       "      <td>400</td>\n",
       "      <td>283</td>\n",
       "      <td>154</td>\n",
       "      <td>63</td>\n",
       "      <td>258</td>\n",
       "      <td>281</td>\n",
       "      <td>trafficlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>road10.png</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>263</td>\n",
       "      <td>trafficlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>road100.png</td>\n",
       "      <td>400</td>\n",
       "      <td>385</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>363</td>\n",
       "      <td>326</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>road101.png</td>\n",
       "      <td>400</td>\n",
       "      <td>200</td>\n",
       "      <td>195</td>\n",
       "      <td>7</td>\n",
       "      <td>392</td>\n",
       "      <td>194</td>\n",
       "      <td>speedlimit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_name  width  height  x_min  y_min  x_max  y_max         label\n",
       "0    road0.png    267     400     98     62    208    232  trafficlight\n",
       "1    road1.png    400     283    154     63    258    281  trafficlight\n",
       "2   road10.png    400     267    106      3    244    263  trafficlight\n",
       "3  road100.png    400     385     35      5    363    326    speedlimit\n",
       "4  road101.png    400     200    195      7    392    194    speedlimit"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"img_name\": img_name_list,\n",
    "        \"width\": width_list,\n",
    "        \"height\": height_list,\n",
    "        \"x_min\": x_min,\n",
    "        \"y_min\": y_min,\n",
    "        \"x_max\": x_max,\n",
    "        \"y_max\": y_max,\n",
    "        \"label\": label_list,\n",
    "    }\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trafficlight': 0, 'speedlimit': 1, 'crosswalk': 2, 'stop': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset[\"label\"].unique().tolist()\n",
    "class_training = {idx: label for idx, label in enumerate(classes)}\n",
    "classes = {label: idx for idx, label in enumerate(classes)}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"class\"] = dataset[\"label\"].map(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>road0.png</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>208</td>\n",
       "      <td>232</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road1.png</td>\n",
       "      <td>400</td>\n",
       "      <td>283</td>\n",
       "      <td>154</td>\n",
       "      <td>63</td>\n",
       "      <td>258</td>\n",
       "      <td>281</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>road10.png</td>\n",
       "      <td>400</td>\n",
       "      <td>267</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>263</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>road100.png</td>\n",
       "      <td>400</td>\n",
       "      <td>385</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>363</td>\n",
       "      <td>326</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>road101.png</td>\n",
       "      <td>400</td>\n",
       "      <td>200</td>\n",
       "      <td>195</td>\n",
       "      <td>7</td>\n",
       "      <td>392</td>\n",
       "      <td>194</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_name  width  height  x_min  y_min  x_max  y_max         label  class\n",
       "0    road0.png    267     400     98     62    208    232  trafficlight      0\n",
       "1    road1.png    400     283    154     63    258    281  trafficlight      0\n",
       "2   road10.png    400     267    106      3    244    263  trafficlight      0\n",
       "3  road100.png    400     385     35      5    363    326    speedlimit      1\n",
       "4  road101.png    400     200    195      7    392    194    speedlimit      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1244it [00:00, 9163.59it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs = defaultdict(list)\n",
    "for idx, dt in tqdm(dataset.iterrows()):\n",
    "    sample_label_list = []\n",
    "    img_name = dt[\"img_name\"]\n",
    "    xmin = int(dt[\"x_min\"])\n",
    "    ymin = int(dt[\"y_min\"])\n",
    "    xmax = int(dt[\"x_max\"])\n",
    "    ymax = int(dt[\"y_max\"])\n",
    "    class_num = dt[\"class\"]\n",
    "    W, H = int(dt[\"width\"]), int(dt[\"height\"])\n",
    "\n",
    "    voc_bbox = (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    x_center, y_center, w, h = pbx.convert_bbox(\n",
    "        voc_bbox, from_type=\"voc\", to_type=\"yolo\", image_size=(W, H)\n",
    "    )\n",
    "\n",
    "    sample_label_list.append(str(class_num))\n",
    "    sample_label_list.append(str(x_center))\n",
    "    sample_label_list.append(str(y_center))\n",
    "    sample_label_list.append(str(w))\n",
    "    sample_label_list.append(str(h))\n",
    "    line = \" \".join(sample_label_list)\n",
    "\n",
    "    imgs[img_name].append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = \"../data/labels\"\n",
    "if os.path.exists(labels_dir):\n",
    "    shutil.rmtree(labels_dir)\n",
    "os.mkdir(labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, lines in imgs.items():\n",
    "    img_name = img_name.split('.')[0]\n",
    "    with open(f'{labels_dir}/{img_name}.txt', 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/train/\"\n",
    "val_dir = \"../data/val\"\n",
    "labels_path = \"../data/labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "if os.path.exists(val_dir):\n",
    "    shutil.rmtree(val_dir)\n",
    "\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "# train, val each containing images and labels folders\n",
    "os.mkdir(train_dir + \"/images\")\n",
    "os.mkdir(train_dir + \"/labels\")\n",
    "os.mkdir(val_dir + \"/images\")\n",
    "os.mkdir(val_dir + \"/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(images_path)\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(files, ratio):\n",
    "    elements = len(files)\n",
    "    middle = int(elements * ratio)\n",
    "    return [files[:middle], files[middle:]]\n",
    "\n",
    "def copy_files(images_path, labels_path, destination_path, files):\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_name = file_name.split('.')[0]\n",
    "\n",
    "        src = images_path + f'/{file_name}.png'\n",
    "        dst = destination_path + '/images'\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "        src = labels_path + f'/{file_name}.txt'\n",
    "        dst = destination_path + '/labels'\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_files, val_files = split(files, train_ratio)\n",
    "\n",
    "root = 'data/traffic_sign_data'\n",
    "\n",
    "copy_files(images_path, labels_path, train_dir, train_files)\n",
    "copy_files(images_path, labels_path, val_dir, val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/sign_data.yaml', 'w') as f:\n",
    "    f.write('train: ../../data/train/images\\n')\n",
    "    f.write('val: ../../data/val/images\\n')\n",
    "    f.write('nc: 4\\n')\n",
    "    f.write(f\"names: {class_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --img 320 --batch 64 --epochs 20 --data ../data/sign_data.yaml --weights yolov5s.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of some problems My PC can't show the progress of the command above then I tried to run it with command prompt and the result are shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\ADMIN\\OneDrive - EPITA\\Project-Demo\\road-sign-detection\\notebooks>python yolov5/train.py --img 320 --batch 64 --epochs 20 --data ../data/sign_data.yaml --weights yolov5s.pt\n",
    "train: weights=yolov5s.pt, cfg=, data=../data/sign_data.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=20, batch_size=64, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
    "github: up to date with https://github.com/ultralytics/yolov5\n",
    "unknown option: -\n",
    "usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n",
    "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
    "           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n",
    "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
    "           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n",
    "           <command> [<args>]\n",
    "YOLOv5  2023-12-4 Python-3.9.13 torch-2.1.0+cpu CPU\n",
    "\n",
    "hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
    "Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
    "TensorBoard: Start with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
    "Overriding model.yaml nc=80 with nc=4\n",
    "\n",
    "                 from  n    params  module                                  arguments\n",
    "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]\n",
    "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]\n",
    "  2                -1  1     18816  models.common.C3                        [64, 64, 1]\n",
    "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]\n",
    "  4                -1  2    115712  models.common.C3                        [128, 128, 2]\n",
    "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]\n",
    "  6                -1  3    625152  models.common.C3                        [256, 256, 3]\n",
    "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]\n",
    "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]\n",
    "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]\n",
    " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
    " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']\n",
    " 12           [-1, 6]  1         0  models.common.Concat                    [1]\n",
    " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]\n",
    " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
    " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']\n",
    " 16           [-1, 4]  1         0  models.common.Concat                    [1]\n",
    " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]\n",
    " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]\n",
    " 19          [-1, 14]  1         0  models.common.Concat                    [1]\n",
    " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]\n",
    " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]\n",
    " 22          [-1, 10]  1         0  models.common.Concat                    [1]\n",
    " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]\n",
    " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
    "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
    "\n",
    "Transferred 343/349 items from yolov5s.pt\n",
    "optimizer: SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
    "train: Scanning C:\\Users\\ADMIN\\OneDrive - EPITA\\Project-Demo\\road-sign-detection\\data\\train\\labels.cache... 657 images,\n",
    "val: Scanning C:\\Users\\ADMIN\\OneDrive - EPITA\\Project-Demo\\road-sign-detection\\data\\val\\labels.cache... 220 images, 0 b\n",
    "\n",
    "AutoAnchor: 5.45 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset\n",
    "Plotting labels to yolov5\\runs\\train\\exp3\\labels.jpg...\n",
    "Image sizes 320 train, 320 val\n",
    "Using 8 dataloader workers\n",
    "Logging results to yolov5\\runs\\train\\exp3\n",
    "Starting training for 20 epochs...\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       0/19         0G     0.1228    0.01454    0.04879         46        320: 100%|██████████| 11/11 [01:05<00:00,  5.\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:09<0\n",
    "                   all        220        317     0.0013       0.31    0.00295   0.000718\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       1/19         0G     0.1023    0.01854    0.03359         41        320: 100%|██████████| 11/11 [00:53<00:00,  4.\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:08<0\n",
    "                   all        220        317      0.821      0.102      0.106     0.0267\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       2/19         0G    0.08426    0.02225    0.02589         55        320: 100%|██████████| 11/11 [00:53<00:00,  4.\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:07<00:00,  3.95s/it]\n",
    "                   all        220        317      0.709      0.143     0.0989     0.0235\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       3/19         0G    0.07246    0.02272     0.0235         58        320: 100%|██████████| 11/11 [00:52<00:00,  4.75s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:07<00:00,  3.83s/it]\n",
    "                   all        220        317      0.445      0.271       0.16     0.0491\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       4/19         0G    0.06494    0.02001    0.01967         50        320: 100%|██████████| 11/11 [00:52<00:00,  4.79s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n",
    "                   all        220        317      0.394      0.334      0.239     0.0953\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       5/19         0G    0.06057    0.01808    0.01563         60        320: 100%|██████████| 11/11 [00:52<00:00,  4.81s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]\n",
    "                   all        220        317      0.756      0.305      0.272      0.111\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       6/19         0G    0.05812    0.01621    0.01368         37        320: 100%|██████████| 11/11 [00:53<00:00,  4.89s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]\n",
    "                   all        220        317      0.806      0.322      0.428      0.207\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       7/19         0G    0.05587     0.0161    0.01223         51        320: 100%|██████████| 11/11 [00:53<00:00,  4.87s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.36s/it]\n",
    "                   all        220        317      0.411      0.638      0.395      0.184\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       8/19         0G    0.05098    0.01385   0.009572         44        320: 100%|██████████| 11/11 [00:52<00:00,  4.80s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.42s/it]\n",
    "                   all        220        317      0.632      0.666      0.607      0.286\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "       9/19         0G    0.04735    0.01305   0.007595         39        320: 100%|██████████| 11/11 [00:53<00:00,  4.84s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]\n",
    "                   all        220        317      0.702      0.619      0.656      0.301\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      10/19         0G    0.04416    0.01173   0.006267         48        320: 100%|██████████| 11/11 [00:55<00:00,  5.03s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n",
    "                   all        220        317      0.599       0.69      0.656      0.337\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      11/19         0G    0.04196    0.01132   0.005493         42        320: 100%|██████████| 11/11 [00:55<00:00,  5.03s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.18s/it]\n",
    "                   all        220        317      0.843      0.687      0.763      0.439\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      12/19         0G    0.03893    0.01087   0.005054         51        320: 100%|██████████| 11/11 [00:54<00:00,  5.00s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]\n",
    "                   all        220        317      0.694      0.701      0.704      0.405\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      13/19         0G    0.03649    0.01051   0.004301         28        320: 100%|██████████| 11/11 [00:54<00:00,  4.99s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]\n",
    "                   all        220        317      0.815      0.755      0.794      0.479\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      14/19         0G    0.03262       0.01   0.004096         33        320: 100%|██████████| 11/11 [00:53<00:00,  4.86s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:05<00:00,  2.95s/it]\n",
    "                   all        220        317      0.805      0.757      0.802      0.478\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      15/19         0G    0.03042   0.009585   0.003447         37        320: 100%|██████████| 11/11 [00:53<00:00,  4.83s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n",
    "                   all        220        317      0.882      0.787      0.847      0.542\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      16/19         0G     0.0282   0.009109   0.003347         41        320: 100%|██████████| 11/11 [00:53<00:00,  4.87s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]\n",
    "                   all        220        317      0.933      0.775      0.866      0.559\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      17/19         0G    0.02676   0.008945   0.003462         39        320: 100%|██████████| 11/11 [00:52<00:00,  4.73s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n",
    "                   all        220        317      0.882      0.805      0.866      0.572\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      18/19         0G    0.02412   0.008744   0.002964         41        320: 100%|██████████| 11/11 [00:52<00:00,  4.79s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:05<00:00,  2.90s/it]\n",
    "                   all        220        317       0.91      0.796      0.873      0.596\n",
    "\n",
    "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
    "      19/19         0G    0.02276   0.008834    0.00272         34        320: 100%|██████████| 11/11 [00:52<00:00,  4.78s/it]\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:05<00:00,  2.96s/it]\n",
    "                   all        220        317      0.928      0.817      0.887      0.608\n",
    "\n",
    "20 epochs completed in 0.341 hours.\n",
    "Optimizer stripped from yolov5\\runs\\train\\exp3\\weights\\last.pt, 14.3MB\n",
    "Optimizer stripped from yolov5\\runs\\train\\exp3\\weights\\best.pt, 14.3MB\n",
    "\n",
    "Validating yolov5\\runs\\train\\exp3\\weights\\best.pt...\n",
    "Fusing layers...\n",
    "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
    "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:06<00:00,  3.15s/it]\n",
    "                   all        220        317      0.927      0.817      0.887      0.608\n",
    "          trafficlight        220         42      0.837      0.786      0.846      0.451\n",
    "            speedlimit        220        203      0.946       0.98      0.988      0.806\n",
    "             crosswalk        220         55      0.925      0.677      0.788      0.488\n",
    "                  stop        220         17          1      0.824      0.927      0.686\n",
    "Results saved to yolov5\\runs\\train\\exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
